{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dae98cf",
   "metadata": {
    "id": "8dae98cf"
   },
   "source": [
    "# Notebook for transformers exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7F4Zm1i0XI-l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7F4Zm1i0XI-l",
    "outputId": "55cf49b7-aea4-4982-d736-f0e3665f374b"
   },
   "outputs": [],
   "source": [
    "# Please ignore this cell: extra install steps that are only executed when running the notebook on Google Colab\n",
    "# flake8-noqa-cell\n",
    "import os\n",
    "if 'google.colab' in str(get_ipython()) and not os.path.isdir('Test_Data'):\n",
    "    # we're running on colab and we haven't already downloaded the test data\n",
    "    # first install pinned version of setuptools (latest version doesn't seem to work with this package on colab)\n",
    "    !pip install setuptools==61 -qqq\n",
    "    # install the moralization package\n",
    "    !pip install git+https://github.com/ssciwr/moralization.git -qqq\n",
    "    # download test data sets\n",
    "    !wget https://github.com/ssciwr/moralization/archive/refs/heads/test_data.zip -q\n",
    "    !mkdir -p data && unzip -qq test_data.zip && mv -f moralization-test_data/*_Data ./data/. && rm -rf moralization-test_data test_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec233e",
   "metadata": {
    "id": "a8ec233e"
   },
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from moralization import input_data as inp\n",
    "from moralization import analyse as ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6415e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07f6415e",
    "outputId": "a2c40de2-fc2e-44c7-e3af-37e1041498ba"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yNkiKJ4jX2Ow",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNkiKJ4jX2Ow",
    "outputId": "bc371799-2b6e-4f2b-a759-55519a6d9559"
   },
   "outputs": [],
   "source": [
    "\n",
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120eff9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "120eff9f",
    "outputId": "fce44c42-340e-417b-806d-b65346ec09ea"
   },
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "raw_data_no_moralization = \"data/All_Data/Alle_bearbeiteten_Annotationen-0_label.csv\"\n",
    "df_raw_no_moralization = pd.read_csv(raw_data_no_moralization)\n",
    "data_dict = inp.InputOutput.read_data(\"data/All_Data/XMI_11\")\n",
    "df_spans = ae.AnalyseOccurrence(data_dict, mode=\"spans\").df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fee4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "865fee4e",
    "outputId": "6e6fbd50-4ddc-41c1-d10d-6702ca186835"
   },
   "outputs": [],
   "source": [
    "df_spans.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spans[\"Gerichtsurteile-neg-AW-neu-optimiert-BB\"].loc[\"KAT2-Moralwerte\",\"Care\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0da479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spans[\"Gerichtsurteile-neg-AW-neu-optimiert-BB\"].loc[\"KAT1-Moralisierendes Segment\",\"Moralisierung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spans[\"Gerichtsurteile-neg-AW-neu-optimiert-BB\"].loc[\"KAT1-Moralisierendes Segment\",\"Keine Moralisierung\"].split(\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c5bd3",
   "metadata": {
    "id": "fb1c5bd3"
   },
   "outputs": [],
   "source": [
    "df_raw_no_moralization = df_raw_no_moralization.rename(\n",
    "    columns={\"Label\": \"Label_moralization\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9d995",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "6de9d995",
    "outputId": "ab34cf5d-1a69-4267-ce08-2b0e30318c28"
   },
   "outputs": [],
   "source": [
    "df_raw_no_moralization.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a137f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "df5a137f",
    "outputId": "b2bf3aa8-c6f8-4fd0-e6cd-7e1e9ec0dd0e"
   },
   "outputs": [],
   "source": [
    "df_spans.loc[\"KAT1-Moralisierendes Segment\"]\n",
    "# all that are not \"Keine Moralisierung\" shall be \"Moralisierung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6978e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90a6978e",
    "outputId": "68884d8a-bdeb-450d-aff1-1685235fd21e"
   },
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "df_new = df_spans.loc[[\"KAT1-Moralisierendes Segment\"]]\n",
    "df_new = df_new.fillna(\"\")\n",
    "# drop the multiindex\n",
    "df_new = df_new.droplevel(0)\n",
    "# sum strings over all sources\n",
    "df_new[\"All sources\"] = \"\"\n",
    "for file in df_new.columns[:-1]:\n",
    "    print(file)\n",
    "    df_new[\"All sources\"] += df_new[file] + \"###\"\n",
    "# extract row content into new dataframe\n",
    "# no moralization\n",
    "df_no_moralization = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Keine Moralisierung\"].split(\"###\"), columns=[\"Sentences\"]\n",
    ")\n",
    "# drop empty rows\n",
    "df_no_moralization = df_no_moralization[df_no_moralization[\"Sentences\"].astype(bool)]\n",
    "df_no_moralization[\"Label_moralization\"] = 0\n",
    "# moralization\n",
    "df_moralization = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Moralisierung\"].split(\"###\"), columns=[\"Sentences\"]\n",
    ")\n",
    "df_moralization = df_moralization[df_moralization[\"Sentences\"].astype(bool)]\n",
    "df_moralization[\"Label_moralization\"] = 1\n",
    "df_moralization_kontext = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Moralisierung Kontext\"].split(\"###\"),\n",
    "    columns=[\"Sentences\"],\n",
    ")\n",
    "df_moralization_kontext = df_moralization_kontext[\n",
    "    df_moralization_kontext[\"Sentences\"].astype(bool)\n",
    "]\n",
    "df_moralization_kontext[\"Label_moralization\"] = 1\n",
    "df_moralization_ww = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Moralisierung Weltwissen\"].split(\"###\"),\n",
    "    columns=[\"Sentences\"],\n",
    ")\n",
    "df_moralization_ww = df_moralization_ww[df_moralization_ww[\"Sentences\"].astype(bool)]\n",
    "df_moralization_ww[\"Label_moralization\"] = 1\n",
    "df_moralization_exp = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Moralisierung explizit\"].split(\"###\"),\n",
    "    columns=[\"Sentences\"],\n",
    ")\n",
    "df_moralization_exp = df_moralization_exp[df_moralization_exp[\"Sentences\"].astype(bool)]\n",
    "df_moralization_exp[\"Label_moralization\"] = 1\n",
    "df_moralization_int = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Moralisierung interpretativ\"].split(\"###\"),\n",
    "    columns=[\"Sentences\"],\n",
    ")\n",
    "df_moralization_int = df_moralization_int[df_moralization_int[\"Sentences\"].astype(bool)]\n",
    "df_moralization_int[\"Label_moralization\"] = 1\n",
    "df_new.to_csv(\"df_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UGMgkLWAtBrT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UGMgkLWAtBrT",
    "outputId": "d1477a3a-c776-41aa-b50a-dbe0c798653c"
   },
   "outputs": [],
   "source": [
    "df_moralization.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b49c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "c81b49c6",
    "outputId": "a635685f-72c4-4ba8-9e07-11b5c5e1f7e2"
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1648f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "99a1648f",
    "outputId": "4ac5a68b-d184-4444-8b7d-33ec7563510f"
   },
   "outputs": [],
   "source": [
    "df_raw_no_moralization.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0d0cb",
   "metadata": {
    "id": "a2e0d0cb"
   },
   "outputs": [],
   "source": [
    "# merge all the data frames into one\n",
    "frames = [\n",
    "    df_raw_no_moralization,\n",
    "    df_no_moralization,\n",
    "    df_moralization,\n",
    "    df_moralization_kontext,\n",
    "    df_moralization_ww,\n",
    "    df_moralization_exp,\n",
    "    df_moralization_int,\n",
    "]\n",
    "all_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911613e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "1911613e",
    "outputId": "f7629392-7512-48f7-cd4b-101ec8cbbd8f"
   },
   "outputs": [],
   "source": [
    "all_data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1b36b",
   "metadata": {
    "id": "eda1b36b"
   },
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4b5a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "44a4b5a5",
    "outputId": "c2c09710-b973-43ab-dddb-724fe4f53258"
   },
   "outputs": [],
   "source": [
    "all_data[\"Label_no_moralization\"] = np.where(all_data[\"Label_moralization\"] == 1, 0, 1)\n",
    "all_data[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1569f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "5b1569f4",
    "outputId": "f966b385-d68a-4e26-bb8d-3585f0ea1846"
   },
   "outputs": [],
   "source": [
    "all_data[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar(\n",
    "    ylim=([0, 2000])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081420b",
   "metadata": {
    "id": "a081420b"
   },
   "source": [
    "## Now we got the data in one frame, let's reshuffle and split into train, test, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fafabb",
   "metadata": {
    "id": "a0fafabb"
   },
   "outputs": [],
   "source": [
    "all_data = all_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49eb9be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "f49eb9be",
    "outputId": "f1f7852b-80a9-418d-bca7-e9ef623c6a6c"
   },
   "outputs": [],
   "source": [
    "all_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8cc8a",
   "metadata": {
    "id": "9ed8cc8a"
   },
   "outputs": [],
   "source": [
    "# split into train, test, validate with 60% train, 20% validation, 20% test\n",
    "train, validate, test = np.split(\n",
    "    all_data.sample(frac=1, random_state=42),\n",
    "    [int(0.6 * len(all_data)), int(0.8 * len(all_data))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77f3c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "0f77f3c1",
    "outputId": "81117370-eb87-4ffe-b666-5a6ca6bbc2c3"
   },
   "outputs": [],
   "source": [
    "train[\"Label_no_moralization\"] = np.where(train[\"Label_moralization\"] == 1, 0, 1)\n",
    "train[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50c85c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "be50c85c",
    "outputId": "0e909d6c-d840-4e1d-8e88-09e95bb5ba41"
   },
   "outputs": [],
   "source": [
    "validate[\"Label_no_moralization\"] = np.where(validate[\"Label_moralization\"] == 1, 0, 1)\n",
    "validate[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3580f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "cb3580f6",
    "outputId": "292786e1-16ca-4cdf-db6a-9a1606804151"
   },
   "outputs": [],
   "source": [
    "test[\"Label_no_moralization\"] = np.where(test[\"Label_moralization\"] == 1, 0, 1)\n",
    "test[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de84aa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200,
     "referenced_widgets": [
      "37b4f5d8468142438b9fda4722a5d606",
      "fecd2fd5527c4b05bccff7195e4c0530",
      "1b0c94fcbaac4911992f08c73b783ead",
      "0c51c371cd2d4f84b39c4329fef23a7b",
      "1dc53e2a1d2d4893891fec9d3ebaa852",
      "2ea89352450147a495ad93c1e4c03507",
      "6a5cbac9b9664abc88fbbdceea74f823",
      "82c9a1701f6748dbaac71effbbe9da20",
      "112d85f81aad4a31aa53a496c8933d02",
      "5f08140f1da24f48af292cc9692c8ddd",
      "5dc21ae59a1444f397ac0c4bf11952c5",
      "21dfc38f2f7a43659a6346c9edf6fef7",
      "f4de44a173354ae7bc191502713dfeda",
      "f1d3badbf77a45bd88f87cd02cac7e81",
      "f23c8d53c6d44b3291a5b0af98b201b0",
      "cdbbef2a7536446ebdd9ff7548c8656d",
      "b7cfaaf6249c4aa596ae997252d86d22",
      "fec95b523a0740bfa0e1ed8a011dc1b3",
      "4ab483bab45d4e849379fb983980c0bb",
      "936b4c32e23342e2978c6b30d16efaad",
      "8a0e681a7e7c40b3ba8e343c6f8a05cf",
      "07c866eda31940bba7af34807dc589f7",
      "70b1f3e099974cc88b9a17eeeb08631c",
      "fa53c1a9cda34da3b8612c7345b6f957",
      "6894b82b6a5d47fc976b458bc63706c3",
      "dc882e210f794341b32c6d4fe3cf0814",
      "d5cf7382b9e34db38133d982e9f8469f",
      "73cbc61ce43d4c29bca388e72eab483e",
      "9cc3f5ec96014170a5929fd280f0ff2b",
      "38978414bfa94b1eac9284b76119f27f",
      "122d528010e64c7181ba75d5f250ae40",
      "98e0efe70f8f441eb9bdb910c93e9577",
      "bbc28c6f1d6f43608e70495da71a09a4",
      "804a21b1fd8c479eb44ff6b625d9caa8",
      "f33a3b47a6f446ca972c3805aef8d214",
      "2745af4a11d743f5bb3ce55f72287f20",
      "db130dd33b9a494fab3ee3b7977bb978",
      "881ade5e535d488a8284d0468d7fa903",
      "1ae55c35f154486792b0ad1325ca6398",
      "eb7aef4c373a408d9fb745cb240980a1",
      "ecd97f67a64b4ca7b62ea979de31c146",
      "81d43450f309443aa521dbdc7479eb00",
      "df7237948f6c4ed89fdfd677250becec",
      "efc43d454fe54d53a7caa6d74d0f3662"
     ]
    },
    "id": "2de84aa3",
    "outputId": "a060608d-1a7a-4187-be20-cf1842f4e92b"
   },
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f24a7",
   "metadata": {
    "id": "0a8f24a7"
   },
   "outputs": [],
   "source": [
    "class M_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self, data, tokenizer, attributes, max_token_len: int = 128, sample=1000\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.attributes = attributes\n",
    "        self.max_token_len = max_token_len\n",
    "        self.sample = sample\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        self.data[\"Label_no_moralization\"] = np.where(\n",
    "            self.data[\"Label_moralization\"] == 1, 0, 1\n",
    "        )\n",
    "        if self.sample is not None:\n",
    "            no_moralization = self.data.loc[self.data[\"Label_no_moralization\"] > 0]\n",
    "            moralization = self.data.loc[self.data[\"Label_no_moralization\"] == 0]\n",
    "            self.data = pd.concat(\n",
    "                [moralization, no_moralization.sample(self.sample, random_state=7)]\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        comment = str(item.Sentences)\n",
    "        attributes = torch.FloatTensor(item[self.attributes])\n",
    "        tokens = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_token_len,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": tokens.input_ids.flatten(),\n",
    "            \"attention_mask\": tokens.attention_mask.flatten(),\n",
    "            \"labels\": attributes,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f82b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "bd8f82b4",
    "outputId": "a5aa0586-ba46-4b93-803a-e4014b00d043"
   },
   "outputs": [],
   "source": [
    "m_data_train = M_Dataset(\n",
    "    train, tokenizer, [\"Label_moralization\", \"Label_no_moralization\"]\n",
    ")\n",
    "m_data_validate = M_Dataset(\n",
    "    validate, tokenizer, [\"Label_moralization\", \"Label_no_moralization\"], sample=None\n",
    ")\n",
    "m_data_train.data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d773cc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d773cc9",
    "outputId": "656da0f4-015c-41ac-d730-7ec69c27235b"
   },
   "outputs": [],
   "source": [
    "m_data_train.__getitem__(0)[\"labels\"].shape, m_data_train.__getitem__(0)[\n",
    "    \"input_ids\"\n",
    "].shape, m_data_train.__getitem__(0)[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147cdae1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "147cdae1",
    "outputId": "fde58d67-1774-4919-a87e-32cff8c84b62"
   },
   "outputs": [],
   "source": [
    "len(m_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3372f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41b3372f",
    "outputId": "d4619914-7646-42c1-9bfe-f21ddfdfcc62"
   },
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "! pip install pytorch-lightning\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1e667",
   "metadata": {
    "id": "a9d1e667"
   },
   "outputs": [],
   "source": [
    "class M_Data_Module(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train,\n",
    "        val,\n",
    "        attributes,\n",
    "        batch_size: int = 16,\n",
    "        max_token_length: int = 128,\n",
    "        model_name=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "        self.val = val\n",
    "        self.attributes = attributes\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_length = max_token_length\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage in (None, \"fit\"):\n",
    "            self.train_dataset = M_Dataset(\n",
    "                self.train, attributes=self.attributes, tokenizer=self.tokenizer\n",
    "            )\n",
    "            self.val_dataset = M_Dataset(\n",
    "                self.val,\n",
    "                attributes=self.attributes,\n",
    "                tokenizer=self.tokenizer,\n",
    "                sample=None,\n",
    "            )\n",
    "        if stage == \"predict\":\n",
    "            self.val_dataset = M_Dataset(\n",
    "                self.val,\n",
    "                attributes=self.attributes,\n",
    "                tokenizer=self.tokenizer,\n",
    "                sample=None,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, num_workers=4, shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, num_workers=4, shuffle=False\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, num_workers=4, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd59827",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fd59827",
    "outputId": "eedcd08d-837c-4a81-83ef-4d375184633a"
   },
   "outputs": [],
   "source": [
    "M_data_module = M_Data_Module(\n",
    "    train, validate, attributes=[\"Label_moralization\", \"Label_no_moralization\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a8c6f",
   "metadata": {
    "id": "8d7a8c6f"
   },
   "outputs": [],
   "source": [
    "M_data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f701f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61f701f9",
    "outputId": "b1828a07-14cb-4894-dc0e-c5e1bdab5caa"
   },
   "outputs": [],
   "source": [
    "M_data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db367dc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db367dc9",
    "outputId": "f6f71cb1-4046-4ae5-dc5e-4228b9303b27"
   },
   "outputs": [],
   "source": [
    "len(M_data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095906a0",
   "metadata": {
    "id": "095906a0"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599f894",
   "metadata": {
    "id": "4599f894"
   },
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "\n",
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchmetrics.functional.classification import auroc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6195f",
   "metadata": {
    "id": "fac6195f"
   },
   "outputs": [],
   "source": [
    "class M_Comment_Classifier(pl.LightningModule):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pretrained_model = AutoModel.from_pretrained(\n",
    "            config[\"model_name\"], return_dict=True\n",
    "        )\n",
    "        self.hidden = torch.nn.Linear(\n",
    "            self.pretrained_model.config.hidden_size,\n",
    "            self.pretrained_model.config.hidden_size,\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(\n",
    "            self.pretrained_model.config.hidden_size, self.config[\"n_labels\"]\n",
    "        )\n",
    "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        self.loss_func = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        # roberta layer\n",
    "        output = self.pretrained_model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "        # final logits\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.hidden(pooled_output)\n",
    "        pooled_output = F.relu(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        # calculate loss\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.loss_func(\n",
    "                logits.view(-1, self.config[\"n_labels\"]),\n",
    "                labels.view(-1, self.config[\"n_labels\"]),\n",
    "            )\n",
    "        return loss, logits\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        self.log(\"train loss \", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        self.log(\"validation loss \", loss, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        return outputs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.config[\"lr\"],\n",
    "            weight_decay=self.config[\"weight_decay\"],\n",
    "        )\n",
    "        total_steps = self.config[\"train_size\"] / self.config[\"batch_size\"]\n",
    "        warmup_steps = math.floor(total_steps * self.config[\"warmup\"])\n",
    "        warmup_steps = math.floor(total_steps * self.config[\"warmup\"])\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, warmup_steps, total_steps\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "# def validation_epoch_end(self, outputs):\n",
    "#   losses = []\n",
    "#   for output in outputs:\n",
    "#     loss = output['val_loss'].detach().cpu()\n",
    "#     losses.append(loss)\n",
    "#   avg_loss = torch.mean(torch.stack(losses))\n",
    "#   self.log(\"avg_val_loss\", avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1821672",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "7d26fd7904c14ac38d8abac68a3a1982",
      "d9e1ae4ef58e4c8d881d3b0340822ec8",
      "83e6ec26a2234638b1b4f53c760a92b3",
      "b1db2131a470429890916481d0d1bb99",
      "2c2269380ab6474fb586fd1b77c26063",
      "ccf43cf93d224e1cadf9e202017e09e0",
      "1a099cd3da2845bd9a8c52b1c3688ae6",
      "c5205a788d2a4271926e75571afd1d35",
      "6e959918abd34c26824f794e0b62b5d8",
      "a4dae84fa7fb432eaf6471bc9bf4138a",
      "3a7bb3f9c87847be98faa5926f6df8a0",
      "143f12806c1e4b97b4b14f7b18cee518",
      "042a9c4315dd47f0a8b0caeffba12e58",
      "54eccdae0ebf4e36999147f5b541a391",
      "f89066775dbf4047975faf7ac6433156",
      "00a7672457f9485dacec0484f53206b5",
      "6804175e5a334dd3824c45e5fc0f072c",
      "817da9f4a7ad4bce892f3a00625d7a89",
      "900433ecb5a44b0ab12c238107217f3b",
      "010b3cfab9874abda956136d59385be7",
      "084029e085cb432c81cc6476c234ade4",
      "4ed4e57f18fa407fa1b235d318068f48"
     ]
    },
    "id": "a1821672",
    "outputId": "1b25a4c3-4da2-4839-f6b6-e55ce988780f"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\",\n",
    "    \"n_labels\": len([\"Label_moralization\", \"Label_no_moralization\"]),\n",
    "    \"batch_size\": 6,\n",
    "    \"lr\": 1.5e-6,\n",
    "    \"warmup\": 0.2,\n",
    "    \"train_size\": len(M_data_module.train_dataloader()),\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"n_epochs\": 100,\n",
    "}\n",
    "\n",
    "model = M_Comment_Classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a7135",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a60a7135",
    "outputId": "69baa759-e0d7-4939-d48f-988f5d06cb27"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "input_ids = m_data_train.__getitem__(idx)[\"input_ids\"]\n",
    "attention_mask = m_data_train.__getitem__(idx)[\"attention_mask\"]\n",
    "labels = m_data_train.__getitem__(idx)[\"labels\"]\n",
    "model.cpu()\n",
    "loss, output = model(\n",
    "    input_ids.unsqueeze(dim=0), attention_mask.unsqueeze(dim=0), labels.unsqueeze(dim=0)\n",
    ")\n",
    "print(labels.shape, output.shape, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e383554",
   "metadata": {
    "id": "0e383554"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7218ef8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7218ef8",
    "outputId": "8d57e6f1-32f9-4af4-8e66-c5d7b2663552"
   },
   "outputs": [],
   "source": [
    "# datamodule\n",
    "m_data_module = M_Data_Module(\n",
    "    train,\n",
    "    validate,\n",
    "    attributes=[\"Label_moralization\", \"Label_no_moralization\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    ")\n",
    "m_data_module.setup()\n",
    "\n",
    "# model\n",
    "model = M_Comment_Classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb313e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4eb313e",
    "outputId": "ce8bde73-2c5a-4b41-e6ec-8d48b5331d1b"
   },
   "outputs": [],
   "source": [
    "# trainer and fit\n",
    "trainer = pl.Trainer(max_epochs=config[\"n_epochs\"], accelerator='gpu', devices=1, num_sanity_val_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb032d3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416,
     "referenced_widgets": [
      "8b011b98b0ad4f0e9e14747915048c30",
      "9f643aeb55fe4666a9262283047633b3",
      "bb8eb9a169a245e293ef4f4ee81b5789",
      "d615a7807426415b846d78c2006e777d",
      "d63c74291884447d91ae6e070d7d1939",
      "b74b1f61613548ca84d64d4a6d962cf6",
      "ef966f00fd6b427bab38f282a2919170",
      "95ee2b228b91480ebd0ee33dd224ab06",
      "e1501df40a974478b0ae67e341956717",
      "f1f7b19e35d442a2aaf9fdb359d5041d",
      "7bef0d7238b64afa91650d4f997e7898",
      "cdef540ec2ef4b059c9368224bdce70e",
      "a5ed1a0406a4492ea35809ee329400fa",
      "9c9ce8dd12d9406f904855cbd8480789",
      "2f6811ce70e742e79fd0db1a7e9ca0bf",
      "601babb31cea4ca0a2599d4dde56e14f",
      "41a7927338da435dba21b742e8cb35a4",
      "ace69a3ffdbb4a29856ed11d4a7278d9",
      "2e297ff002874a7ea38d41a9f4ebb99a",
      "e08dc9c68e774bcaa5347307ec6fef3d",
      "72e8eb1decce44a495d82e0adf9d926b",
      "dd077f5eac5d4afeb0a1575770434951"
     ]
    },
    "id": "eb032d3a",
    "outputId": "e941fe85-6713-4f5e-ac23-29efb681bc21"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, m_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fddcb2f",
   "metadata": {
    "id": "4fddcb2f"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d9c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = torch.tensor([1,2,3])\n",
    "foo = foo.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8cd064",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89198ae",
   "metadata": {
    "id": "b89198ae"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"random_try\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afMJChsoM6H5",
   "metadata": {
    "id": "afMJChsoM6H5"
   },
   "source": [
    "- Either pipeline (to simplify things) or load components manually - tokenizer (convert text to numbers), automodel with correct headers (ie classification) (model architecture and weights from pre-training)  \n",
    "- UNK (unknown) token for words not in vocab  \n",
    "- tokenizer is model-specific and contains certain algorithm and vocabulary for each model  \n",
    "- tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "- tokenizer(\"Using a Transformer network is simple\")  \n",
    "- tokenizer.save_pretrained(\"directory_on_my_computer\")\n",
    "- tokenization is followed by encoding\n",
    "- batches of text need to be padded, and attention mask indicates which tokens are padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2e666",
   "metadata": {
    "id": "smBvA5pPNJEA"
   },
   "source": [
    "# Second try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e007a87",
   "metadata": {},
   "source": [
    "## Data\n",
    "Here, each sentence has one label. If I understand it correctly, each TOKEN needs to have one label in the training. So, if a sequence is classified as \"moralization\", then all the tokens in that sequence need to be assigned the label \"1\", and all other tokens \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "# import data as spacy doc and take it from there\n",
    "from moralization import spacy_model\n",
    "data_dir = \"../data/All_Data/XMI_11\"\n",
    "test_setup = spacy_model.SpacySetup(data_dir, working_dir=\"./test\")\n",
    "data_doc = test_setup.convert_data_to_spacy_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abdeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert doc and span objects into list of tokens and labels\n",
    "# span.start returns the token id in the doc\n",
    "# data_doc = test_setup.doc_dict\n",
    "# print(data_doc.keys())\n",
    "example_name = list(data_doc.keys())[0]\n",
    "for span in data_doc[example_name][\"train\"].spans[\"task1\"]:\n",
    "    print(\"**********\")\n",
    "    print(span)\n",
    "    print(span.label_)\n",
    "    print(span.start)\n",
    "    print(data_doc[example_name][\"train\"][span.start], data_doc[example_name][\"train\"][span.end-1], \"mmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb41213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and label\n",
    "# either list of sentences with list of tokens - here spacy needs to initialize with sentencizer\n",
    "# or list of instances with list of tokens\n",
    "# the instances must not be too long for this!\n",
    "# with sentences:\n",
    "# tokenlist = [[token.text for token in sent] for sent in data_doc[example_name][\"train\"].sents]\n",
    "# find the three \"#\" tokens and split there\n",
    "# if there is only one \"#\" it marks a word that is generally associated with moralization\n",
    "# but not a break between instances\n",
    "# we cannot split the strings before the tokenization because that will mess up the span\n",
    "# alignment\n",
    "# we could use spacy's matcher for this but unfortunately then we need to run the pipeline again\n",
    "# maybe something to add to the spacy module to to initially?\n",
    "# For now generate list of tokens and set all labels to zero\n",
    "tokenlist = [token for token in data_doc[example_name][\"train\"]]\n",
    "labellist = [0 for i in range(0,len(tokenlist))]\n",
    "split_instances = []\n",
    "for i, token in enumerate(tokenlist):\n",
    "    if token.text == \"#\":\n",
    "        # check if next two tokens are also \"#\"\n",
    "        # these can never be in the beginning or end of a doc \n",
    "        # but in principle we should check that\n",
    "        # sometimes there are also more than three \"#\" but we just split once anyways\n",
    "        # hashtags get removed later\n",
    "        if tokenlist[i+1].text == \"#\" and tokenlist[i+2].text == \"#\":\n",
    "#             print(\"Found instance break: {}, {}, {}, {}, {}\".format(tokenlist[i-2].text,\n",
    "#                                                                     tokenlist[i-1].text,\n",
    "#                                                                     token.text,\n",
    "#                                                                     tokenlist[i+1].text,\n",
    "#                                                                     tokenlist[i+2].text))\n",
    "            # save the token id where we will split\n",
    "            # we need to take care not to save two ids\n",
    "            # so maybe we save a tuple of all \"#\" positions\n",
    "            split_instances.append((i, i+1, i+2))\n",
    "# now check for overlap in any tuples and remove the ones that overlap\n",
    "# (424, 425, 426)\n",
    "# (425, 426, 427)\n",
    "# (426, 427, 428) should become \n",
    "# (424, 425, 426)\n",
    "\n",
    "elements_to_remove = []\n",
    "for i in range(0, len(split_instances)-2):\n",
    "    # check that we are not reaching the end of the list\n",
    "    # check if i and i+i contain same numbers\n",
    "    # create a set of i and i+1 and find difference\n",
    "    my_diff = set(split_instances[i]) - set(split_instances[i+1])\n",
    "    if len(my_diff) < 3:\n",
    "#         print(\"Found matching sets! {} {}\".format(split_instances[i], split_instances[i+1]))\n",
    "#         print(\"Marking the next instance split for removal ...\")\n",
    "        elements_to_remove.append(i+1)\n",
    "# print(elements_to_remove)\n",
    "for item in reversed(elements_to_remove):\n",
    "#     print(\"keep\", split_instances[item-1])\n",
    "#     print(\"remove\", split_instances[item])\n",
    "    # Now delete all of these in the list of tuples\n",
    "    del split_instances[item]\n",
    "    \n",
    "# check the list of instance splits again\n",
    "# print(split_instances)\n",
    "for i in range(0, len(split_instances)-2):\n",
    "    # check that we are not reaching the end of the list\n",
    "    # check if i and i+i contain same numbers\n",
    "    # create a set of i and i+1 and find difference\n",
    "    my_diff = set(split_instances[i]) - set(split_instances[i+1])\n",
    "    if len(my_diff) != 3:\n",
    "        print(\"Found duplicate!\", my_diff, split_instances[i], split_instances[i+1])\n",
    "\n",
    "# generate the labels based on the current list of tokens\n",
    "# now set all Moralisierung, Moralisierung Kontext, \n",
    "# Moralisierung explizit, Moralisierung interpretativ, Moralisierung Weltwissen to 1\n",
    "selected_labels = [\"Moralisierung\", \"Moralisierung Kontext\", \"Moralisierung Weltwissen\",\n",
    "                  \"Moralisierung explizit\", \"Moralisierung interpretativ\"]\n",
    "for span in data_doc[example_name][\"train\"].spans[\"task1\"]:\n",
    "    if span.label_ in selected_labels:\n",
    "        labellist[span.start+1:span.end] = [1] * (span.end-span.start)\n",
    "        # mark the beginning of a span with 2\n",
    "        labellist[span.start] = 2\n",
    "        # here we could also mark punctuation but we will leave that for after the \n",
    "        # transformers tokenizer\n",
    "# now punctuation needs a label of -100\n",
    "# for i, token in enumerate(tokenlist):\n",
    "#     print(token.text, token.is_punct)\n",
    "#     if token.is_punct:\n",
    "#         labellist[i] = -100\n",
    "        \n",
    "# for token, label in zip(tokenlist, labellist):\n",
    "#     print(token.text, label)\n",
    "\n",
    "# convert token into token.text\n",
    "wordlist = [token.text for token in tokenlist]\n",
    "templist = list(zip(wordlist, labellist))\n",
    "instance_list = []\n",
    "# Now we can generate a list of instances which is a list of tokens\n",
    "for i, item in enumerate(split_instances):\n",
    "    j = split_instances[i-1][0] if i > 0 else 0\n",
    "    temp = templist[j:item[0]]\n",
    "    instance_list.append(temp)\n",
    "\n",
    "words = []\n",
    "labels = []\n",
    "# print(instance_list)\n",
    "# unpack the tuples into two lists of lists\n",
    "for mylist in instance_list:\n",
    "    wordlists, labellists = zip(*mylist)\n",
    "    words.append(wordlists)\n",
    "    labels.append(labellists)\n",
    "\n",
    "print(words[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make this a dict so it can be written to json and submitted to datasets\n",
    "# data_set = {}\n",
    "# for i, (token, label) in enumerate(zip(tokenlist,labellist)):    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "templist = list(zip(words[0], labels[0]))\n",
    "print(templist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up unnecessary tokens: remove \"#\"\n",
    "# remove function does not work here as it only removes the first one\n",
    "clean_list = [i for i in templist if i != (\"#\", 0) and i != (\"#\", 1)] \n",
    "print(clean_list)\n",
    "# disentangle the tuples again\n",
    "tokenlist, labellist = zip(*cleanlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[15:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can feed this into the tokenizer\n",
    "inputs = tokenizer(words[16], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(inputs.word_ids(), labels[16])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labellist needs to be expanded to cover the new tokens\n",
    "# beginning of a span needs a different label than inside of a span\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label == 2:\n",
    "                label -= 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2112ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids = inputs.word_ids()\n",
    "print(align_labels_with_tokens(labels[16], word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(words, labels):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        words, truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    new_labels = []\n",
    "    for i, label in enumerate(labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(label, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = []\n",
    "for wordlist, labellist in zip(words, labels):\n",
    "    print(wordlist)\n",
    "    print(labellist)\n",
    "    tokenized_dataset.append(tokenize_and_align_labels(wordlist, labellist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1af50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenize_and_align_labels(words, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e6de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_dataset[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762e0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
