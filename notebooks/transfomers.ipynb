{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dae98cf",
   "metadata": {},
   "source": [
    "# Notebook for transformers exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from moralization import input as inp\n",
    "from moralization import analyse as ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120eff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "raw_data_no_moralization = (\n",
    "    \"../../moralization-notes/Alle_bearbeiteten_Annotationen-0_label.csv\"\n",
    ")\n",
    "df_raw_no_moralization = pd.read_csv(raw_data_no_moralization)\n",
    "data_dict = inp.InputOutput.read_data(\"../data/All_Data/XMI_11\")\n",
    "df_spans = ae.AnalyseOccurrence(data_dict, mode=\"spans\").df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spans.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_no_moralization = df_raw_no_moralization.rename(\n",
    "    columns={\"Label\": \"Label_moralization\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_no_moralization.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spans.loc[\"KAT1-Moralisierendes Segment\"]\n",
    "# all that are not \"Keine Moralisierung\" shall be \"Moralisierung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "df_new = df_spans.loc[[\"KAT1-Moralisierendes Segment\"]]\n",
    "# drop the multiindex\n",
    "df_new = df_new.droplevel(0)\n",
    "# sum strings over all sources\n",
    "df_new[\"All sources\"] = \"\"\n",
    "for file in df_new.columns[:-1]:\n",
    "    print(file)\n",
    "    df_new[\"All sources\"] += df_new[file] + \"###\"\n",
    "# extract row content into new dataframe\n",
    "# no moralization\n",
    "df_no_moralization = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Keine Moralisierung\"].split(\"###\"), columns=[\"Sentences\"]\n",
    ")\n",
    "# drop empty rows\n",
    "df_no_moralization = df_no_moralization[df_no_moralization[\"Sentences\"].astype(bool)]\n",
    "df_no_moralization[\"Label_moralization\"] = 0\n",
    "# moralization\n",
    "df_moralization = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Moralisierung\"].split(\"###\"), columns=[\"Sentences\"]\n",
    ")\n",
    "df_moralization = df_moralization[df_moralization[\"Sentences\"].astype(bool)]\n",
    "df_moralization[\"Label_moralization\"] = 1\n",
    "df_moralization_exp = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Moralisierung explizit\"].split(\"###\"),\n",
    "    columns=[\"Sentences\"],\n",
    ")\n",
    "df_moralization_exp = df_moralization_exp[df_moralization_exp[\"Sentences\"].astype(bool)]\n",
    "df_moralization_exp[\"Label_moralization\"] = 1\n",
    "df_moralization_int = pd.DataFrame(\n",
    "    df_new[\"All sources\"].loc[\"Moralisierung interpretativ\"].split(\"###\"),\n",
    "    columns=[\"Sentences\"],\n",
    ")\n",
    "df_moralization_int = df_moralization_int[df_moralization_int[\"Sentences\"].astype(bool)]\n",
    "df_moralization_int[\"Label_moralization\"] = 1\n",
    "df_new.to_csv(\"df_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_no_moralization.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the data frames into one\n",
    "frames = [\n",
    "    df_raw_no_moralization,\n",
    "    df_no_moralization,\n",
    "    df_moralization,\n",
    "    df_moralization_exp,\n",
    "    df_moralization_int,\n",
    "]\n",
    "all_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1b36b",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Label_no_moralization\"] = np.where(all_data[\"Label_moralization\"] == 1, 0, 1)\n",
    "all_data[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar(\n",
    "    ylim=([0, 2000])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081420b",
   "metadata": {},
   "source": [
    "## Now we got the data in one frame, let's reshuffle and split into train, test, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fafabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49eb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test, validate with 60% train, 20% validation, 20% test\n",
    "train, validate, test = np.split(\n",
    "    all_data.sample(frac=1, random_state=42),\n",
    "    [int(0.6 * len(all_data)), int(0.8 * len(all_data))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Label_no_moralization\"] = np.where(train[\"Label_moralization\"] == 1, 0, 1)\n",
    "train[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate[\"Label_no_moralization\"] = np.where(validate[\"Label_moralization\"] == 1, 0, 1)\n",
    "validate[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3580f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Label_no_moralization\"] = np.where(test[\"Label_moralization\"] == 1, 0, 1)\n",
    "test[[\"Label_moralization\", \"Label_no_moralization\"]].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de84aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self, data, tokenizer, attributes, max_token_len: int = 128, sample=1000\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.attributes = attributes\n",
    "        self.max_token_len = max_token_len\n",
    "        self.sample = sample\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        self.data[\"Label_no_moralization\"] = np.where(\n",
    "            self.data[\"Label_moralization\"] == 1, 0, 1\n",
    "        )\n",
    "        if self.sample is not None:\n",
    "            no_moralization = self.data.loc[self.data[\"Label_no_moralization\"] > 0]\n",
    "            moralization = self.data.loc[self.data[\"Label_no_moralization\"] == 0]\n",
    "            self.data = pd.concat(\n",
    "                [moralization, no_moralization.sample(self.sample, random_state=7)]\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        comment = str(item.Sentences)\n",
    "        attributes = torch.FloatTensor(item[self.attributes])\n",
    "        tokens = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_token_len,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": tokens.input_ids.flatten(),\n",
    "            \"attention_mask\": tokens.attention_mask.flatten(),\n",
    "            \"labels\": attributes,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f82b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data_train = M_Dataset(\n",
    "    train, tokenizer, [\"Label_moralization\", \"Label_no_moralization\"]\n",
    ")\n",
    "m_data_validate = M_Dataset(\n",
    "    validate, tokenizer, [\"Label_moralization\", \"Label_no_moralization\"], sample=None\n",
    ")\n",
    "m_data_train.data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d773cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data_train.__getitem__(0)[\"labels\"].shape, m_data_train.__getitem__(0)[\n",
    "    \"input_ids\"\n",
    "].shape, m_data_train.__getitem__(0)[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147cdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M_Data_Module(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train,\n",
    "        val,\n",
    "        attributes,\n",
    "        batch_size: int = 16,\n",
    "        max_token_length: int = 128,\n",
    "        model_name=\"roberta-base\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "        self.val = val\n",
    "        self.attributes = attributes\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_length = max_token_length\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage in (None, \"fit\"):\n",
    "            self.train_dataset = M_Dataset(\n",
    "                self.train, attributes=self.attributes, tokenizer=self.tokenizer\n",
    "            )\n",
    "            self.val_dataset = M_Dataset(\n",
    "                self.val,\n",
    "                attributes=self.attributes,\n",
    "                tokenizer=self.tokenizer,\n",
    "                sample=None,\n",
    "            )\n",
    "        if stage == \"predict\":\n",
    "            self.val_dataset = M_Dataset(\n",
    "                self.val,\n",
    "                attributes=self.attributes,\n",
    "                tokenizer=self.tokenizer,\n",
    "                sample=None,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, num_workers=4, shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, num_workers=4, shuffle=False\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, num_workers=4, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd59827",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_data_module = M_Data_Module(\n",
    "    train, validate, attributes=[\"Label_moralization\", \"Label_no_moralization\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f701f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db367dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(M_data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095906a0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "\n",
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchmetrics.functional.classification import auroc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M_Comment_Classifier(pl.LightningModule):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pretrained_model = AutoModel.from_pretrained(\n",
    "            config[\"model_name\"], return_dict=True\n",
    "        )\n",
    "        self.hidden = torch.nn.Linear(\n",
    "            self.pretrained_model.config.hidden_size,\n",
    "            self.pretrained_model.config.hidden_size,\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(\n",
    "            self.pretrained_model.config.hidden_size, self.config[\"n_labels\"]\n",
    "        )\n",
    "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        self.loss_func = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        # roberta layer\n",
    "        output = self.pretrained_model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "        # final logits\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.hidden(pooled_output)\n",
    "        pooled_output = F.relu(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        # calculate loss\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.loss_func(\n",
    "                logits.view(-1, self.config[\"n_labels\"]),\n",
    "                labels.view(-1, self.config[\"n_labels\"]),\n",
    "            )\n",
    "        return loss, logits\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        self.log(\"train loss \", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        self.log(\"validation loss \", loss, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, outputs = self(**batch)\n",
    "        return outputs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.config[\"lr\"],\n",
    "            weight_decay=self.config[\"weight_decay\"],\n",
    "        )\n",
    "        total_steps = self.config[\"train_size\"] / self.config[\"batch_size\"]\n",
    "        warmup_steps = math.floor(total_steps * self.config[\"warmup\"])\n",
    "        warmup_steps = math.floor(total_steps * self.config[\"warmup\"])\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, warmup_steps, total_steps\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "# def validation_epoch_end(self, outputs):\n",
    "#   losses = []\n",
    "#   for output in outputs:\n",
    "#     loss = output['val_loss'].detach().cpu()\n",
    "#     losses.append(loss)\n",
    "#   avg_loss = torch.mean(torch.stack(losses))\n",
    "#   self.log(\"avg_val_loss\", avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1821672",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"distilroberta-base\",\n",
    "    \"n_labels\": len([\"Label_moralization\", \"Label_no_moralization\"]),\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 1.5e-6,\n",
    "    \"warmup\": 0.2,\n",
    "    \"train_size\": len(M_data_module.train_dataloader()),\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"n_epochs\": 100,\n",
    "}\n",
    "\n",
    "model = M_Comment_Classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "input_ids = m_data_train.__getitem__(idx)[\"input_ids\"]\n",
    "attention_mask = m_data_train.__getitem__(idx)[\"attention_mask\"]\n",
    "labels = m_data_train.__getitem__(idx)[\"labels\"]\n",
    "model.cpu()\n",
    "loss, output = model(\n",
    "    input_ids.unsqueeze(dim=0), attention_mask.unsqueeze(dim=0), labels.unsqueeze(dim=0)\n",
    ")\n",
    "print(labels.shape, output.shape, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e383554",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7218ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule\n",
    "m_data_module = M_Data_Module(\n",
    "    train,\n",
    "    validate,\n",
    "    attributes=[\"Label_moralization\", \"Label_no_moralization\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    ")\n",
    "m_data_module.setup()\n",
    "\n",
    "# model\n",
    "model = M_Comment_Classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer and fit\n",
    "trainer = pl.Trainer(max_epochs=config[\"n_epochs\"], gpus=4, num_sanity_val_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb032d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, m_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fddcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89198ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
